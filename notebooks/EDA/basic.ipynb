{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(r\"F:\\machine learning\\mlops\\end to end machine learning pipeline\\MLOPs_workflow\\data\\raw\\AB_NYC_2019.csv\")\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                name  host_id host_name  \\\n",
       "0  2539  Clean & quiet apt home by the park     2787      John   \n",
       "1  2595               Skylit Midtown Castle     2845  Jennifer   \n",
       "\n",
       "  neighbourhood_group neighbourhood  latitude  longitude        room_type  \\\n",
       "0            Brooklyn    Kensington  40.64749  -73.97237     Private room   \n",
       "1           Manhattan       Midtown  40.75362  -73.98377  Entire home/apt   \n",
       "\n",
       "   price  minimum_nights  number_of_reviews last_review  reviews_per_month  \\\n",
       "0    149               1                  9  2018-10-19               0.21   \n",
       "1    225               1                 45  2019-05-21               0.38   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               6               365  \n",
       "1                               2               355  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2539, 'Clean & quiet apt home by the park', 2787, 'John',\n",
       "        'Brooklyn', 'Kensington', 40.64749, -73.97237, 'Private room',\n",
       "        149, 1, 9, '2018-10-19', 0.21, 6, 365],\n",
       "       [2595, 'Skylit Midtown Castle', 2845, 'Jennifer', 'Manhattan',\n",
       "        'Midtown', 40.75362, -73.98377, 'Entire home/apt', 225, 1, 45,\n",
       "        '2019-05-21', 0.38, 2, 355],\n",
       "       [3647, 'THE VILLAGE OF HARLEM....NEW YORK !', 4632, 'Elisabeth',\n",
       "        'Manhattan', 'Harlem', 40.80902, -73.9419, 'Private room', 150,\n",
       "        3, 0, nan, nan, 1, 365],\n",
       "       [3831, 'Cozy Entire Floor of Brownstone', 4869, 'LisaRoxanne',\n",
       "        'Brooklyn', 'Clinton Hill', 40.68514, -73.95976,\n",
       "        'Entire home/apt', 89, 1, 270, '2019-07-05', 4.64, 1, 194],\n",
       "       [5022, 'Entire Apt: Spacious Studio/Loft by central park', 7192,\n",
       "        'Laura', 'Manhattan', 'East Harlem', 40.79851, -73.94399,\n",
       "        'Entire home/apt', 80, 10, 9, '2018-11-19', 0.1, 1, 0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48895 entries, 0 to 48894\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              48895 non-null  int64  \n",
      " 1   name                            48879 non-null  object \n",
      " 2   host_id                         48895 non-null  int64  \n",
      " 3   host_name                       48874 non-null  object \n",
      " 4   neighbourhood_group             48895 non-null  object \n",
      " 5   neighbourhood                   48895 non-null  object \n",
      " 6   latitude                        48895 non-null  float64\n",
      " 7   longitude                       48895 non-null  float64\n",
      " 8   room_type                       48895 non-null  object \n",
      " 9   price                           48895 non-null  int64  \n",
      " 10  minimum_nights                  48895 non-null  int64  \n",
      " 11  number_of_reviews               48895 non-null  int64  \n",
      " 12  last_review                     38843 non-null  object \n",
      " 13  reviews_per_month               38843 non-null  float64\n",
      " 14  calculated_host_listings_count  48895 non-null  int64  \n",
      " 15  availability_365                48895 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def delta_date_feature(dates):\n",
    "    \"\"\"\n",
    "    Given a 2D array containing dates, returns the delta in days between each date \n",
    "    and the most recent date in its column.\n",
    "    \"\"\"\n",
    "    dates = pd.DataFrame(x, columns=[\"last_review\"])\n",
    "    dates['last_review'] = pd.to_datetime(dates[\"last_review\"], format=f\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    max_dates = dates['last_review'].max()\n",
    "    return dates['last_review'].apply(lambda d : (max_dates - d)).dt.days.fillna(max_dates).to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "def get_feature_transformation_pipeline():\n",
    "    \"\"\"\n",
    "    Constructs a feature transformation pipeline.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    feature_transformation_pipeline : Pipeline\n",
    "        Scikit-learn pipeline for feature preprocessing.\n",
    "    processed_features : list\n",
    "        List of input features before transformation.\n",
    "    new_features : list\n",
    "        List of transformed feature names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Categorical Features\n",
    "    ordinal_categorical = [\"room_type\"]\n",
    "    non_ordinal_categorical = [\"neighbourhood_group\"]\n",
    "\n",
    "    ordinal_categorical_preproc = OrdinalEncoder()\n",
    "\n",
    "    non_ordinal_categorical_preproc = make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    )\n",
    "\n",
    "    # Numerical Features with Zero Imputation\n",
    "    zero_imputed = [\n",
    "        \"minimum_nights\",\n",
    "        \"number_of_reviews\",\n",
    "        \"reviews_per_month\",\n",
    "        \"calculated_host_listings_count\",\n",
    "        \"availability_365\",\n",
    "        \"longitude\",\n",
    "        \"latitude\"\n",
    "    ]\n",
    "    zero_imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "\n",
    "    # Date Transformation\n",
    "    date_imputer = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='2010-01-01'),\n",
    "        FunctionTransformer(delta_date_feature, validate=False)\n",
    "    )\n",
    "\n",
    "    # Text Feature Engineering for 'name' column\n",
    "    name_tfidf = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=\"\"),\n",
    "        FunctionTransformer(lambda x: x.ravel(), validate=False),  # Ensures 1D input for TF-IDF\n",
    "        TfidfVectorizer(binary=False, max_features=5, stop_words='english')\n",
    "    )\n",
    "\n",
    "    # Column Transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"ordinal_cat\", ordinal_categorical_preproc, ordinal_categorical),\n",
    "            (\"non_ordinal_cat\", non_ordinal_categorical_preproc, non_ordinal_categorical),\n",
    "            (\"impute_zero\", zero_imputer, zero_imputed),\n",
    "            (\"transform_date\", date_imputer, [\"last_review\"]),\n",
    "            (\"transform_name\", name_tfidf, [\"name\"])\n",
    "        ],\n",
    "        remainder=\"drop\"  # Drops unused columns\n",
    "    )\n",
    "\n",
    "    # Feature Lists\n",
    "    processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + [\"last_review\", \"name\"]\n",
    "\n",
    "    new_features = ordinal_categorical + \\\n",
    "                   ['neighbourhood_group_Bronx', 'neighbourhood_group_Brooklyn', \n",
    "                    'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens', \n",
    "                    'neighbourhood_group_Staten Island'] + \\\n",
    "                   zero_imputed + ['last_review'] + \\\n",
    "                   ['apartment', 'bedroom', 'cozy', 'private', 'room']\n",
    "\n",
    "    # Final Pipeline\n",
    "    feature_transformation_pipeline = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor)]\n",
    "    )\n",
    "\n",
    "    return feature_transformation_pipeline, processed_features, new_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, processed_features, new_features = get_feature_transformation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_name, step in pipeline.named_steps.items():\n",
    "    print(f\"🔍 Checking step: {step_name}\")\n",
    "    try:\n",
    "        transformed = step.fit_transform(data)\n",
    "        print(f\" Step '{step_name}' completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error in step '{step_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "parquet_file_path = Path(\"F://machine learning//mlops//end to end machine learning pipeline//MLOPs_workflow//data//processed//target.parquet\")\n",
    "\n",
    "data = pd.read_parquet(parquet_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'id', 'event_timestamp'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'room_type', 'neighbourhood_group_Bronx',\n",
    "       'neighbourhood_group_Brooklyn', 'neighbourhood_group_Manhattan',\n",
    "       'neighbourhood_group_Queens', 'id', 'event_timestamp']\n",
    "\n",
    "\n",
    "'neighbourhood_group_Staten Island', 'minimum_nights',\n",
    "       'number_of_reviews', 'reviews_per_month', 'id', 'event_timestamp'\n",
    "\n",
    "\n",
    "'calculated_host_listings_count', 'availability_365', 'longitude',\n",
    "       'latitude', 'id', 'event_timestamp'\n",
    "\n",
    "\n",
    "'last_review', 'apartment', 'bedroom', 'cozy', 'private', 'room', 'id',\n",
    "       'event_timestamp'\n",
    "\n",
    "\n",
    "'price', 'id', 'event_timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Features\n",
    "ordinal_categorical = [\"room_type\"]\n",
    "non_ordinal_categorical = [\"neighbourhood_group\"]\n",
    "\n",
    "ordinal_categorical_preproc = OrdinalEncoder()\n",
    "\n",
    "non_ordinal_categorical_preproc = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features with Zero Imputation\n",
    "zero_imputed = [\n",
    "    \"minimum_nights\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "    \"calculated_host_listings_count\",\n",
    "    \"availability_365\",\n",
    "    \"longitude\",\n",
    "    \"latitude\"\n",
    "]\n",
    "zero_imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "\n",
    "# Date Transformation\n",
    "date_imputer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='2010-01-01'),\n",
    "    FunctionTransformer(delta_date_feature, validate=False)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date_imputer.fit_transform(data[[\"last_review\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SimpleImputer(strategy='constant', fill_value='2010-01-01').fit_transform(data[[\"last_review\"]])\n",
    "# dates = FunctionTransformer(delta_date_feature, validate=False).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(pd.DataFrame(x, columns=[\"last_review\"]))\n",
    "# max_dates = date_sanitized.max()\n",
    "# return date_sanitized.apply(lambda d: (max_dates - d.fillna(max_dates)).dt.days, axis=0).values\n",
    "dates = pd.DataFrame(x, columns=[\"last_review\"])\n",
    "\n",
    "dates['last_review'] = pd.to_datetime(dates['last_review'], format=f\"%Y-%m-%d\", errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         262\n",
       "1          48\n",
       "2        3475\n",
       "3           3\n",
       "4         231\n",
       "         ... \n",
       "48890    3475\n",
       "48891    3475\n",
       "48892    3475\n",
       "48893    3475\n",
       "48894    3475\n",
       "Name: last_review, Length: 48895, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dates = dates['last_review'].max()\n",
    "\n",
    "dates['last_review'].apply(lambda d : (max_dates - d)).dt.days.fillna(max_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
